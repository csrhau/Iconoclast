\section*{Introduction}
Driven by Moore's Law, advances in processor design have delivered improvements in CPU performance for decades. As physical limits are reached, however, refinements to the same basic technologies are beginning to show diminishing returns. One side-effect of this is an unsustainable rise in system power usage, which the US Department of Energy has identified as a primary constraint for exascale systems \cite{shalf:2011aa}.

Hardware manufacturers are already prioritising energy efficiency in their processor designs~\cite{kurd:2014aa}. In turn, some groups have suggested that software modifications will be required to fully exploit the energy efficiency improvements of modern processors~\cite{shao:2013aa}. This is analogous to the current practice of tuning code for reduced runtime by exploiting specific processor features like vectorisation or cache hierarchy. These groups expect targeted optimisation to be applied to reducing power consumption in the future.

A body of research is accumulating as the search for techniques to identify and reason about software power optimizations continues. The intent of this paper is to provide a critical review of the field; identifying the opportunities present and highlighting the amount of benefit which can be realistically expected of them. We approach this task in two ways. Firstly we review the prior art in this field to identify any trends and secondly we provide an empirical investigation, applying some of the proposed techniques in order to understand how they may benefit developers.

The remainder of this paper is organized as follows: Section~\ref{sec:background} details the problem background and introduces some core concepts and metrics. Section~\ref{sec:prior} gives an overview of prior research carried out in this area. Section~\ref{sec:profiling} then investigates how the techniques described in Section~\ref{sec:prior} may be applied practically.\todo{finish, condense}
