\section{Notes}

\todo{\begin{enumerate}
\item Merge this delta section - use for snippets
\item Consider moving Code optimization out of intro
\item Optimizable range is only a small part of this part
\item Write a clear limitations section

\end{enumerate}
}



\todo{Say how the baseline does not include halts, but halted states are time dependent only }
\begin{figure}
\label{fig:tlpilp}
\includegraphics[width=0.9\linewidth]{./Plots/tlp_vs_ilp/tlpilp-figure0.pdf}
\caption{Power Overhead from TLP and ILP}
\end{figure}

\todo{Make comment about how reducing the activity factor is in some sense counter to time optimization - that doing more per unit time is better. }


\todo{Energy Measurement and Prediction for Multi-threaded Programs -- this gives a simple model based on power modelling and claims sub 10 \%}


\todo{citation S. Kaxiras and M. Martonosi, Computer Architecture Techniques for Power-Efficiency, 1st ed. Morgan and
Claypool Publishers, 2008.

The end of Dennard scaling is expected to shrink the range of DVFS in future nodes, limiting the energy savings of this technique. This paper evaluates how much we can increase the effectiveness of DVFS by using a software decoupled access-execute approach. Decoupling the data access from execution allows us to apply optimal voltage-frequency selection for each phase and therefore improve energy efficiency over standard coupled execution.
}
\todo{Cite this paper for dennard: A 30 Year Retrospective on Dennard's MOSFET Scaling Paper}

\reword{Dennard scaling, which roughly, that as transistors get smaller their power density stays constant, so that the power use stays in proportion with area: both voltage and current scale (downward) with length \todo{cite Dennard's paper}}

\fragment{When viewed in this context, all event-driven power models are simply linking performance events back to their associated activity costs/factors}


\reword{The uncore is a collection of components of a processor
not in the core but essential for core performance. The
CPU core contains components involved in executing in-
structions, including execution units, L1 and L2 cache,
branch prediction logic, etc. Uncore functions include
the last level cache (LLC), integrated memory controllers
(IMC), on-chip interconnect (OCI), power control logic
(PWR), etc. as shown in Figure 1. With growing cache
sizes and the integration of various SoC components on
CPU die, the uncore is becoming an increasingly impor-
tant contributor to total SoC power.}









\todo{PMB2014 checkpointing paper - exascale expects 70\% of energy to go to memory dimms.}









\todo{PMBS2014 checkpointing paper 2 - extreme low or high frequency higher failure rate per job.}

\todo{Destroy this: Models and Metrics to Enable Energy-Efficiency Optimizations}







%\begin{table}
%\centering
%\small
%\begin{tabular}{@{}lll@{}} \toprule
%&\multicolumn{2}{c}{Granularity} \\ \cmidrule(r){2-3}
%Approach & Instruction Level & Architecture Level \\ %\midrule
%Measurement & Hanhel et. al.~\cite{hahnel:2012aa}  & %\todo{find eg}\\
%Perf. Counters & Shao \& Brooks~\cite{shao:2013aa} & %Isci \& Martonosi~\cite{isci:2003aa} \\
%Simulation &  Tiwari et. al.~\cite{tiwari:1994aa} & Li et. al.~\cite{li:2009aa} \\
%Analytical Modelling & Hong et. al.~\cite{hong:2010aa} %& Karkhanis \& Smith~\cite{karkhanis:2007aa} \\
%\bottomrule
%\end{tabular}
 % \caption{Energy Estimation Taxonomy}
  %\label{tab:taxonomy}
%d\end{table}







